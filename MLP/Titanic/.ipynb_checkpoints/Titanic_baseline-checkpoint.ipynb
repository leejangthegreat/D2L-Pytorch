{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f005384b-0535-4187-b274-5a075eb48814",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c051911e-29d8-4d0d-9f2a-82a9c89d8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2c4aec-1af8-4006-904c-80d2441d957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12) (418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6236a9a-7c53-43e2-9b85-48e3e761cead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[0:4, :])\n",
    "print([c for c in train_data])\n",
    "print([c for c in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a84dd5-8e6c-43b3-9845-9d3f09f53ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat((train_data.iloc[:, 2:], test_data.iloc[:, 1:]))\n",
    "# 保留除Survived标签与ID以外的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899ac784-6a62-4818-a720-80f2a38dce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 10)\n",
      "   Pclass                                               Name     Sex   Age  \\\n",
      "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
      "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
      "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
      "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
      "\n",
      "   SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0      1      0         A/5 21171   7.2500   NaN        S  \n",
      "1      1      0          PC 17599  71.2833   C85        C  \n",
      "2      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      1      0            113803  53.1000  C123        S  \n"
     ]
    }
   ],
   "source": [
    "print(all_features.shape)\n",
    "print(all_features.iloc[:4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16197f1a-6371-4df1-a243-8b335757e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = train_data.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd4416e5-b3dd-403f-b5cc-c9ab22d9342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Numeric features\n",
    "numeric_index = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "\n",
    "# Feature Normalization: E = 0, S2 = 1\n",
    "all_features[numeric_index] = all_features[numeric_index].apply(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13dc0761-adba-4340-bdb3-7e77fe6a62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass                                               Name     Sex  \\\n",
      "0  0.841595                            Braund, Mr. Owen Harris    male   \n",
      "1 -1.545507  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
      "2  0.841595                             Heikkinen, Miss. Laina  female   \n",
      "3 -1.545507       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
      "\n",
      "        Age     SibSp     Parch            Ticket      Fare Cabin Embarked  \n",
      "0 -0.546789  0.481104 -0.444829         A/5 21171 -0.503210   NaN        S  \n",
      "1  0.563282  0.481104 -0.444829          PC 17599  0.733941   C85        C  \n",
      "2 -0.269271 -0.478904 -0.444829  STON/O2. 3101282 -0.490169   NaN        S  \n",
      "3  0.355144  0.481104 -0.444829            113803  0.382632  C123        S  \n"
     ]
    }
   ],
   "source": [
    "print(all_features.iloc[:4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26b717cc-e3d4-4a80-86c3-ab6098603159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill N/A with 0 if data is unbiased\n",
    "all_features[numeric_index] = all_features[numeric_index].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b4cf79b-d192-4456-939b-1470505e4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dummy features\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6fb8d99-a9e8-4316-982a-49cc4f944046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 2437)\n"
     ]
    }
   ],
   "source": [
    "print(all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d17c27b7-5a51-43ae-aa69-e2ddd7d76fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Numpy Metrix from Pandas Table\n",
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)\n",
    "train_labels = torch.tensor(all_labels.values.reshape(-1, 1), dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "319a03c2-cb98-4ee6-b561-38f1faad8141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0145232-9678-47cf-9e2b-413ef587b96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2437, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Module components\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "dim_inputs = train_features.shape[1]  # The feature number of one sample\n",
    "net = nn.Sequential(nn.Linear(dim_inputs, 2))\n",
    "\n",
    "\n",
    "def init_weight(N):\n",
    "    if isinstance(N, nn.Linear):\n",
    "        nn.init.normal_(N.weight, std=0.01)\n",
    "\n",
    "\n",
    "net.apply(init_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79e3d0be-62dc-4450-8c7e-9763b0055d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = (y_hat.type(y.dtype) == y)\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01018eeb-c64e-4be6-a600-f9ca3357c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, data_iter):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()\n",
    "    metric = d2l.Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(d2l.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c451b65-33b4-4226-9670-d05ac6bc6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "         num_epoches, lr, weight_dacay, batch_size):\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "    train_iter = d2l.load_array((train_features, train_labels), batch_size)\n",
    "    optim = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=weight_dacay)\n",
    "    for epoch in range(num_epoches):\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for X, y in train_iter:\n",
    "            optim.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y.reshape(-1))\n",
    "            l.sum().backward()\n",
    "            optim.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.mean() * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            train_acc.append(metric[1] / metric[2])\n",
    "            train_loss.append(metric[0] / metric[2])\n",
    "        if test_labels is not None:\n",
    "            test_iter = d2l.load_array((test_features, test_labels), batch_size)\n",
    "            test_acc.append(evaluate(net, test_iter))\n",
    "    return train_acc, test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bc93340-49da-47f7-bb6b-47b21a40b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_slice(k, fold_idx, X, y):\n",
    "    assert k > 1\n",
    "    X_train, y_train, X_valid, y_valid = None, None, None, None\n",
    "    fold_size = X.shape[0] // k\n",
    "    for i in range(k):\n",
    "        idx = slice(i * fold_size, (i + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if i == fold_idx:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.concat([X_train, X_part], 0)\n",
    "            y_train = torch.concat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bf0dd20-374e-4257-8fe5-385ecb37c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_train(net, features, labels, num_epoches, lr, weight_decay, batch_size, k):\n",
    "    \"\"\"Train k fold on training dataset\"\"\"\n",
    "    train_acc_sum, valid_acc_sum = 0, 0\n",
    "    for fold in range(k):\n",
    "        train_features, train_labels, test_features, test_labels = fold_slice(k, fold, features, labels)\n",
    "        train_acc, test_acc, train_loss = train(net, train_features, train_labels, \n",
    "                                                test_features, test_labels, num_epoches, \n",
    "                                                lr, weight_decay, batch_size)\n",
    "        train_acc_sum += train_acc[-1]\n",
    "        valid_acc_sum += test_acc[-1]\n",
    "        print(f\"第{fold + 1}折：训练精度 {float(train_acc[-1]):f}, 训练损失 {float(train_loss[-1]):f}, 测试精度 {float(test_acc[-1]):f}\")\n",
    "    return train_acc_sum / k, valid_acc_sum / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bcd3d4d-bfa2-40f3-ae07-37bdf2c90b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1折：训练精度 16.553371, 训练损失 29.061514, 测试精度 17.483146\n",
      "第2折：训练精度 17.171348, 训练损失 26.397211, 测试精度 16.876404\n",
      "第3折：训练精度 16.926966, 训练损失 26.275846, 测试精度 16.707865\n",
      "第4折：训练精度 17.061798, 训练损失 27.176772, 测试精度 16.393258\n",
      "第5折：训练精度 16.553371, 训练损失 37.496035, 测试精度 17.943820\n",
      "5 折交叉验证，平均训练精度 16.853371，平均验证精度 17.080899\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "num_epoches = 100\n",
    "lr = 0.1\n",
    "weight_decay = 2\n",
    "batch_size = 32\n",
    "train_acc, valid_acc = k_fold_train(net, train_features, train_labels, num_epoches, lr, weight_decay, batch_size, k)\n",
    "print(f\"{k} 折交叉验证，平均训练精度 {float(train_acc):f}，平均验证精度 {float(valid_acc):f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2671f5-9bcd-4041-b982-19807edb108a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
